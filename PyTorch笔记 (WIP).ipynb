{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LearningPyTorch\n",
    "What do you call a pie that caught on fire in the oven?\n",
    "\n",
    "__A Py-Torch.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dependencies\n",
    "\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `torch` package\n",
    "这个部分会含括`torch`的基本数学功能，比如张量和张量操作。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "一个一维张量：\n",
      "tensor([1, 2, 3])\n",
      "\n",
      "一个二维张量：\n",
      "tensor([[1, 2],\n",
      "        [3, 4]])\n"
     ]
    }
   ],
   "source": [
    "# 张量（tensor）是一个任何维度的数组/矩阵（和numpy的array差不多）\n",
    "\n",
    "tensor = torch.tensor([1, 2, 3])\n",
    "tensor_2d = torch.tensor([[1, 2], [3, 4]])\n",
    "\n",
    "print(f'一个一维张量：\\n{tensor}\\n')\n",
    "print(f'一个二维张量：\\n{tensor_2d}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "基础加法: tensor([1, 2, 3]) + 1 = tensor([2, 3, 4])\n",
      "\n",
      "乘法和次方是基于每个元素的: tensor([1, 2, 3]) ** 2 = tensor([1, 4, 9])\n",
      "\n",
      "点乘: tensor([1, 2, 3]) ⋅ tensor([1, 2, 3]) = 14\n",
      "\n",
      "位运算: tensor([1, 2, 3]) << 2 = tensor([ 4,  8, 12])\n"
     ]
    }
   ],
   "source": [
    "# 张量可以被用于数学运算\n",
    "\n",
    "tensor = torch.tensor([1, 2, 3])\n",
    "\n",
    "print(f'基础加法: {tensor} + 1 = {tensor + 1}\\n')\n",
    "print(f'乘法和次方是基于每个元素的: {tensor} ** 2 = {tensor ** 2}\\n')\n",
    "print(f'点乘: {tensor} ⋅ {tensor} = {tensor.dot(tensor)}\\n')\n",
    "print(f'位运算: {tensor} << 2 = {tensor << 2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "操作之后原来的张量：tensor([ 49, 529, 682])\n",
      "操作的结果：tensor([149, 629, 782])\n",
      "\n",
      "操作之后原来的张量：tensor([149, 629, 782])\n",
      "操作的结果：tensor([149, 629, 782])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 张量这个类里还有一些实用的函数\n",
    "\n",
    "# 正常情况下，这些函数的运算结果（一个新的张量）会被函数返回；但是，当在个别函数名后加上\n",
    "# 下划线（‘_’），函数的运算结果则会覆盖原来的变量的值，并返回该变量。\n",
    "\n",
    "# 没有‘_’\n",
    "tensor = torch.tensor([49, 529, 682]) # my favorite SCPs (owo)\n",
    "result = tensor.add(100)\n",
    "print(f'操作之后原来的张量：{tensor}')\n",
    "print(f'操作的结果：{result}\\n')\n",
    "# 运算后原来的张量的值不变\n",
    "\n",
    "# 有‘_’\n",
    "tensor = torch.tensor([49, 529, 682])\n",
    "result = tensor.add_(100)\n",
    "print(f'操作之后原来的张量：{tensor}')\n",
    "print(f'操作的结果：{result}\\n')\n",
    "# 现在，result和tensor指向的object是同一个"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "获取一个张量的元素的数量：6\n",
      "获取一个张量的形状：torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "# 想获取关于一个张量的信息也很容易\n",
    "\n",
    "tensor = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "\n",
    "print(f'获取一个张量的元素的数量：{torch.numel(tensor)}')\n",
    "print(f'获取一个张量的形状：{tensor.shape}')\n",
    "# 获取形状用tensor.size()也可以，并且在与运算相关的字节码上没有区别，但是不推荐，\n",
    "# 因为tensor.shape更贴近于numpy的风格，而numpy的风格正在逐渐转换成行业规范"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3])\n",
      "tensor([[1, 2],\n",
      "        [3, 4]])\n",
      "对张量的操作会反映在NumPy数组里：[100   2   3]\n"
     ]
    }
   ],
   "source": [
    "# 创建张量的方式有很多，之前的代码中也有torch.tensor的调用方法\n",
    "\n",
    "# Python列表式\n",
    "tensor = torch.tensor([1, 2, 3])\n",
    "print(tensor)\n",
    "\n",
    "# NumPy数组式\n",
    "array = np.array([[1, 2], [3, 4]])\n",
    "tensor = torch.tensor(array)\n",
    "print(tensor)\n",
    "\n",
    "# 注意：torch.tensor是对传入的参数进行拷贝后创建新的张量\n",
    "# 对新创建的张量进行改动不会影响原来的张量，并且用torch.tensor创建张量的时间复杂度至少O(N)\n",
    "\n",
    "# 假设想在不进行拷贝的情况下通过NumPy数组建立张量，可以使用torch.as_tensor\n",
    "array = np.array([1, 2, 3])\n",
    "tensor = torch.as_tensor(array)\n",
    "tensor[0] = 100\n",
    "print(f'对张量的操作会反映在NumPy数组里：{array}')\n",
    "\n",
    "# 还可以复制一个张量\n",
    "tensor = torch.tensor([5, 6, 7])\n",
    "new_tensor = tensor.clone().detach() # detach会把张量从原来的graph中脱离（详细请见autograd实现方式）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "转化成NumPy数组：[1 2 3]\n",
      "转化成Python列表：[1, 2, 3]\n",
      "从单个元素张量里获取元素的值：5.0\n"
     ]
    }
   ],
   "source": [
    "# 张量的转换\n",
    "\n",
    "tensor = torch.tensor([1, 2, 3])\n",
    "single_value_tensor = torch.tensor(5.0)\n",
    "\n",
    "print(f'转化成NumPy数组：{tensor.numpy()}')\n",
    "print(f'转化成Python列表：{tensor.tolist()}')\n",
    "print(f'从单个元素张量里获取元素的值：{single_value_tensor.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "从1到2，并每次增加0.2：tensor([1.0000, 1.2000, 1.4000, 1.6000, 1.8000])\n",
      "\n",
      "从10到20之间均匀分布的5个点：tensor([10.0000, 12.5000, 15.0000, 17.5000, 20.0000])\n",
      "\n",
      "5 * 5的identity矩阵：\n",
      "tensor([[1., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 1.]])\n",
      "\n",
      "全是99.5：\n",
      "tensor([[[99.5000, 99.5000],\n",
      "         [99.5000, 99.5000],\n",
      "         [99.5000, 99.5000]],\n",
      "\n",
      "        [[99.5000, 99.5000],\n",
      "         [99.5000, 99.5000],\n",
      "         [99.5000, 99.5000]]])\n",
      "\n",
      "全是0：\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "全是1：\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "# 快捷创建张量\n",
    "\n",
    "# 标明[起点, 终点)、以及每次增加的step，可以生成从起点到终点，并每个元素之间增加step的张量\n",
    "#（长度为(end - start) / step）\n",
    "print(f'从1到2，并每次增加0.2：{torch.arange(1, 2, 0.2)}\\n')\n",
    "# torch.arange和torch.range作用一样，但是后者已经deprecated\n",
    "\n",
    "# 标明[起点, 终点]、以及总共元素的数量(steps)，可以生成在该范围内均匀分布的steps个元素的张量\n",
    "print(f'从10到20之间均匀分布的5个点：{torch.linspace(10, 20, 5)}\\n')\n",
    "\n",
    "# 生成二维的identity矩阵\n",
    "print(f'5 * 5的identity矩阵：\\n{torch.eye(5)}\\n')\n",
    "\n",
    "# 生成全是某个值的张量\n",
    "print(f'全是99.5：\\n{torch.full((2, 3, 2), 99.5)}\\n')\n",
    "\n",
    "# 生成全是0或1的张量\n",
    "print(f'全是0：\\n{torch.zeros((2, 3))}')\n",
    "print(f'全是1：\\n{torch.zeros((2, 3))}')\n",
    "# 虽然在有torch.fill的基础上，这两个函数看起来没有什么存在的意义，但是zeros和ones是从NumPy\n",
    "# 中演变出来的习俗，所以挺酷的"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 拓展\n",
    "这部分中大部分的函数都是用在torch内部的（或是用于基于torch的库），并不会在Intro to ML课程中特别用到。假如对torch内部不感兴趣的学员可以跳过这一段。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 一些关于tensor的属性和操作\n",
    "\n",
    "tensor = torch.tensor([1, 2, 3])\n",
    "\n",
    "# 判断一个变量是否为torch的张量\n",
    "torch.is_tensor(tensor) # True\n",
    "torch.is_tensor([2, 3, 4]) # False \n",
    "\n",
    "# 判断一个变量是否为torch的储存类型\n",
    "# torch的储存类型通常是一个继承_StorageBase和与自己对应的C底层类的子类\n",
    "torch.is_storage(torch.DoubleStorage()) # True\n",
    "torch.is_storage(tensor) # False\n",
    "# 储存类型并不携带任何semantics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 改变tensor默认的float dtype （data type）\n",
    "\n",
    "print(f'tensor默认的float dtype是float32: {torch.tensor([1.0, 2.0]).dtype}\\n')\n",
    "\n",
    "# 把默认改成float64\n",
    "torch.set_default_dtype(torch.float64)\n",
    "\n",
    "print(f'更改之后的dtype: {torch.tensor([1.0, 2.0]).dtype}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
